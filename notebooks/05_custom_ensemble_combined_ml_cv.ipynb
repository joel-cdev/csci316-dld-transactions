{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqymBKIaYm3_",
        "outputId": "9d5d3856-b9db-4769-e7bd-97c27dd00c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"CSCI316_Project1_Regression_4_2\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark version:\", spark.version)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AotYQO04ZPpJ",
        "outputId": "b7fc6f53-2c74-41d4-c5b1-5ca46d27983f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PARQUET_DIR = \"/content/drive/MyDrive/cleaned_parquet\"\n",
        "\n",
        "import os\n",
        "parquet_files = [f for f in os.listdir(PARQUET_DIR) if f.endswith(\".parquet\")]\n",
        "print(\"Parquet files found:\", len(parquet_files))\n",
        "print(parquet_files[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49zySz_pZPmy",
        "outputId": "1ea309fb-3b6a-4ed7-caa8-f21d6b219c59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parquet files found: 200\n",
            "['part-00172-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00194-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00185-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00188-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00196-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00178-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00169-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00182-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00193-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00159-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00199-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00167-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00195-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00161-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00191-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00155-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00190-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00180-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00157-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet', 'part-00181-1fd552f4-5ba5-48c4-ad91-1cb3b7309ccc-c000.snappy.parquet']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.parquet(PARQUET_DIR)\n",
        "print(\"Loaded parquet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqaSZxETZPkV",
        "outputId": "4a5490c5-4e29-4ea1-eb0e-8b95373633a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Schema:\")\n",
        "df.printSchema()\n",
        "\n",
        "print(\"\\nRow count:\", df.count())\n",
        "\n",
        "print(\"\\nSample rows:\")\n",
        "df.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L30VaAwOa7Gx",
        "outputId": "dac60c9e-62f3-49e6-a3fa-667c31df3cd7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema:\n",
            "root\n",
            " |-- transaction_id: string (nullable = true)\n",
            " |-- procedure_id: integer (nullable = true)\n",
            " |-- trans_group_id: integer (nullable = true)\n",
            " |-- trans_group_ar: string (nullable = true)\n",
            " |-- trans_group_en: string (nullable = true)\n",
            " |-- procedure_name_ar: string (nullable = true)\n",
            " |-- procedure_name_en: string (nullable = true)\n",
            " |-- instance_date: string (nullable = true)\n",
            " |-- property_type_id: integer (nullable = true)\n",
            " |-- property_type_ar: string (nullable = true)\n",
            " |-- property_type_en: string (nullable = true)\n",
            " |-- property_sub_type_id: integer (nullable = true)\n",
            " |-- property_sub_type_ar: string (nullable = true)\n",
            " |-- property_sub_type_en: string (nullable = true)\n",
            " |-- property_usage_ar: string (nullable = true)\n",
            " |-- property_usage_en: string (nullable = true)\n",
            " |-- reg_type_id: integer (nullable = true)\n",
            " |-- reg_type_ar: string (nullable = true)\n",
            " |-- reg_type_en: string (nullable = true)\n",
            " |-- area_id: integer (nullable = true)\n",
            " |-- area_name_ar: string (nullable = true)\n",
            " |-- area_name_en: string (nullable = true)\n",
            " |-- building_name_ar: string (nullable = true)\n",
            " |-- building_name_en: string (nullable = true)\n",
            " |-- project_number: string (nullable = true)\n",
            " |-- project_name_ar: string (nullable = true)\n",
            " |-- project_name_en: string (nullable = true)\n",
            " |-- master_project_en: string (nullable = true)\n",
            " |-- master_project_ar: string (nullable = true)\n",
            " |-- nearest_landmark_ar: string (nullable = true)\n",
            " |-- nearest_landmark_en: string (nullable = true)\n",
            " |-- nearest_metro_ar: string (nullable = true)\n",
            " |-- nearest_metro_en: string (nullable = true)\n",
            " |-- nearest_mall_ar: string (nullable = true)\n",
            " |-- nearest_mall_en: string (nullable = true)\n",
            " |-- rooms_ar: string (nullable = true)\n",
            " |-- rooms_en: string (nullable = true)\n",
            " |-- has_parking: integer (nullable = true)\n",
            " |-- procedure_area: double (nullable = true)\n",
            " |-- actual_worth: double (nullable = true)\n",
            " |-- meter_sale_price: double (nullable = true)\n",
            " |-- rent_value: double (nullable = true)\n",
            " |-- meter_rent_price: double (nullable = true)\n",
            " |-- no_of_parties_role_1: integer (nullable = true)\n",
            " |-- no_of_parties_role_2: integer (nullable = true)\n",
            " |-- no_of_parties_role_3: integer (nullable = true)\n",
            " |-- instance_ts: timestamp (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            " |-- month: integer (nullable = true)\n",
            " |-- dow: integer (nullable = true)\n",
            "\n",
            "\n",
            "Row count: 30173\n",
            "\n",
            "Sample rows:\n",
            "+-----------------+------------+--------------+--------------+--------------+--------------------------+-------------------------+-------------+----------------+----------------+----------------+--------------------+--------------------+--------------------+-----------------+-----------------+-----------+----------------+-------------------+-------+--------------+------------------+--------------------------+----------------------+--------------+--------------------------+---------------------------+--------------------------+---------------------------------+---------------------------------+----------------------------+------------------------+--------------------------+---------------+------------------+--------+--------+-----------+--------------+------------+----------------+----------+----------------+--------------------+--------------------+--------------------+-----------+----+-----+----+\n",
            "|transaction_id   |procedure_id|trans_group_id|trans_group_ar|trans_group_en|procedure_name_ar         |procedure_name_en        |instance_date|property_type_id|property_type_ar|property_type_en|property_sub_type_id|property_sub_type_ar|property_sub_type_en|property_usage_ar|property_usage_en|reg_type_id|reg_type_ar     |reg_type_en        |area_id|area_name_ar  |area_name_en      |building_name_ar          |building_name_en      |project_number|project_name_ar           |project_name_en            |master_project_en         |master_project_ar                |nearest_landmark_ar              |nearest_landmark_en         |nearest_metro_ar        |nearest_metro_en          |nearest_mall_ar|nearest_mall_en   |rooms_ar|rooms_en|has_parking|procedure_area|actual_worth|meter_sale_price|rent_value|meter_rent_price|no_of_parties_role_1|no_of_parties_role_2|no_of_parties_role_3|instance_ts|year|month|dow |\n",
            "+-----------------+------------+--------------+--------------+--------------+--------------------------+-------------------------+-------------+----------------+----------------+----------------+--------------------+--------------------+--------------------+-----------------+-----------------+-----------+----------------+-------------------+-------+--------------+------------------+--------------------------+----------------------+--------------+--------------------------+---------------------------+--------------------------+---------------------------------+---------------------------------+----------------------------+------------------------+--------------------------+---------------+------------------+--------+--------+-----------+--------------+------------+----------------+----------+----------------+--------------------+--------------------+--------------------+-----------+----+-----+----+\n",
            "|2-110-2010-1654  |110         |2             |رهون          |Mortgages     |تسجيل إيجارة تنتهى بالتملك|Lease to Own Registration|05-07-2010   |3               |وحدة            |Unit            |60                  |شقه سكنيه           |Flat                |سكني             |Residential      |1          |العقارات القائمة|Existing Properties|390    |برج خليفة     |Burj Khalifa      |8 بوليفارد واك            |8 BLVD WALK           |null          |NULL                      |NULL                       |DownTown Dubai            |داون تاون دبي                    |وسط مدينة دبي                    |Downtown Dubai              |محطة مترو الخليج التجاري|Business Bay Metro Station|مول دبي        |Dubai Mall        |غرفتين  |2 B/R   |1          |151.8         |867007.0    |5711.51         |867007.0  |5711.51         |2                   |2                   |4                   |NULL       |NULL|NULL |NULL|\n",
            "|2-110-2009-200255|110         |2             |رهون          |Mortgages     |تسجيل إيجارة تنتهى بالتملك|Lease to Own Registration|24-02-2009   |3               |وحدة            |Unit            |60                  |شقه سكنيه           |Flat                |سكني             |Residential      |1          |العقارات القائمة|Existing Properties|343    |ورسان الاولى  |Al Warsan First   |يو - 02                   |U-02                  |null          |NULL                      |NULL                       |International City Phase 1|المدينة العالمية - المرحلة الاولى|NULL                             |NULL                        |محطة مترو الراشدية      |Rashidiya Metro Station   |سيتي سنتر مردف |City Centre Mirdif|استوديو |Studio  |0          |76.0          |201640.0    |2653.16         |201640.0  |2653.16         |2                   |2                   |2                   |NULL       |NULL|NULL |NULL|\n",
            "|2-37-2007-100109 |37          |2             |رهون          |Mortgages     |تحويل إيجارة تنتهى بالتملك|Lease to Own Transfer    |14-08-2007   |4               |فيلا            |Villa           |4                   |فيلا                |Villa               |سكني             |Residential      |1          |العقارات القائمة|Existing Properties|352    |الثنيه الرابعة|Al Thanayah Fourth|NULL                      |NULL                  |1046          |روعة الإمارات? الينابيع 9 |Emirates Living - Springs 9|Springs - 2               |الينابيع - 2                     |أكاديمية المدينة الرياضية للسباحة|Sports City Swimming Academy|محطة مترو النخيل        |Nakheel Metro Station     |مارينا مول     |Marina Mall       |غرفتين  |2 B/R   |0          |356.3         |1119825.0   |3142.93         |1119825.0 |3142.93         |2                   |0                   |0                   |NULL       |NULL|NULL |NULL|\n",
            "|2-110-2018-559   |110         |2             |رهون          |Mortgages     |تسجيل إيجارة تنتهى بالتملك|Lease to Own Registration|04-09-2018   |3               |وحدة            |Unit            |60                  |شقه سكنيه           |Flat                |سكني             |Residential      |1          |العقارات القائمة|Existing Properties|348    |القوز الرابعه |Al Goze Fourth    |الخـيـــل هايـتـــس 5A-5B |AL KHAIL HEIGHTS 5A-5B|1527          |الخيل هايتس               |AL KHAIL HEIGHTS           |NULL                      |NULL                             |وسط مدينة دبي                    |Downtown Dubai              |محطة مترو نور بنك       |Noor Bank Metro Station   |مول دبي        |Dubai Mall        |غرفتين  |2 B/R   |1          |159.3         |581944.0    |3653.13         |581944.0  |3653.13         |2                   |2                   |2                   |NULL       |NULL|NULL |NULL|\n",
            "|2-110-2007-100127|110         |2             |رهون          |Mortgages     |تسجيل إيجارة تنتهى بالتملك|Lease to Own Registration|02-07-2007   |4               |فيلا            |Villa           |4                   |فيلا                |Villa               |سكني             |Residential      |1          |العقارات القائمة|Existing Properties|352    |الثنيه الرابعة|Al Thanayah Fourth|NULL                      |NULL                  |1035          |روعة الإمارات ? الينابيع 5|Emirates Living - Springs 5|Springs - 4               |الينابيع - 4                     |أكاديمية المدينة الرياضية للسباحة|Sports City Swimming Academy|محطة مترو النخيل        |Nakheel Metro Station     |مارينا مول     |Marina Mall       |ثلاث غرف|3 B/R   |0          |531.29        |941510.0    |1772.12         |941510.0  |1772.12         |2                   |2                   |4                   |NULL       |NULL|NULL |NULL|\n",
            "+-----------------+------------+--------------+--------------+--------------+--------------------------+-------------------------+-------------+----------------+----------------+----------------+--------------------+--------------------+--------------------+-----------------+-----------------+-----------+----------------+-------------------+-------+--------------+------------------+--------------------------+----------------------+--------------+--------------------------+---------------------------+--------------------------+---------------------------------+---------------------------------+----------------------------+------------------------+--------------------------+---------------+------------------+--------+--------+-----------+--------------+------------+----------------+----------+----------------+--------------------+--------------------+--------------------+-----------+----+-----+----+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Create real date column from the string\n",
        "df2 = df.withColumn(\"instance_date_dt\", F.to_date(F.col(\"instance_date\"), \"dd-MM-yyyy\"))\n",
        "\n",
        "\n",
        "df2.select(\"instance_date\", \"instance_date_dt\").show(10, truncate=False)\n",
        "\n",
        "# Create consistent feature columns (year/month/dow)\n",
        "df2 = (\n",
        "    df2.withColumn(\"year\", F.year(\"instance_date_dt\"))\n",
        "       .withColumn(\"month\", F.month(\"instance_date_dt\"))\n",
        "       .withColumn(\"dow\", F.dayofweek(\"instance_date_dt\"))\n",
        ")\n",
        "\n",
        "df2.select(\"instance_date\", \"instance_date_dt\", \"year\", \"month\", \"dow\").show(10, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tvGdvHla7DU",
        "outputId": "1a808742-0526-4214-b7b3-4f8d8b47d16a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----------------+\n",
            "|instance_date|instance_date_dt|\n",
            "+-------------+----------------+\n",
            "|05-07-2010   |2010-07-05      |\n",
            "|24-02-2009   |2009-02-24      |\n",
            "|14-08-2007   |2007-08-14      |\n",
            "|04-09-2018   |2018-09-04      |\n",
            "|02-07-2007   |2007-07-02      |\n",
            "|26-10-2009   |2009-10-26      |\n",
            "|25-07-2011   |2011-07-25      |\n",
            "|01-03-2010   |2010-03-01      |\n",
            "|29-03-2010   |2010-03-29      |\n",
            "|13-06-2018   |2018-06-13      |\n",
            "+-------------+----------------+\n",
            "only showing top 10 rows\n",
            "+-------------+----------------+----+-----+---+\n",
            "|instance_date|instance_date_dt|year|month|dow|\n",
            "+-------------+----------------+----+-----+---+\n",
            "|05-07-2010   |2010-07-05      |2010|7    |2  |\n",
            "|24-02-2009   |2009-02-24      |2009|2    |3  |\n",
            "|14-08-2007   |2007-08-14      |2007|8    |3  |\n",
            "|04-09-2018   |2018-09-04      |2018|9    |3  |\n",
            "|02-07-2007   |2007-07-02      |2007|7    |2  |\n",
            "|26-10-2009   |2009-10-26      |2009|10   |2  |\n",
            "|25-07-2011   |2011-07-25      |2011|7    |2  |\n",
            "|01-03-2010   |2010-03-01      |2010|3    |2  |\n",
            "|29-03-2010   |2010-03-29      |2010|3    |2  |\n",
            "|13-06-2018   |2018-06-13      |2018|6    |4  |\n",
            "+-------------+----------------+----+-----+---+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "label_col = \"meter_sale_price\"\n",
        "numeric_cols = [\"procedure_area\", \"has_parking\", \"year\", \"month\", \"dow\"]\n",
        "cat_cols = [\"area_name_en\", \"nearest_metro_en\", \"nearest_mall_en\", \"nearest_landmark_en\",\n",
        "            \"property_type_en\", \"rooms_en\"]\n",
        "\n",
        "needed_cols = [label_col] + numeric_cols + cat_cols\n",
        "\n",
        "missing_exprs = [F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in needed_cols]\n",
        "missing_row2 = df2.select(missing_exprs).collect()[0].asDict()\n",
        "missing_row2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYz1hJwoNifx",
        "outputId": "e9acc84f-f659-480c-9e38-bcf81678b8d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'meter_sale_price': 0,\n",
              " 'procedure_area': 0,\n",
              " 'has_parking': 0,\n",
              " 'year': 0,\n",
              " 'month': 0,\n",
              " 'dow': 0,\n",
              " 'area_name_en': 0,\n",
              " 'nearest_metro_en': 6837,\n",
              " 'nearest_mall_en': 6872,\n",
              " 'nearest_landmark_en': 1627,\n",
              " 'property_type_en': 0,\n",
              " 'rooms_en': 418}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "label_col = \"meter_sale_price\"\n",
        "\n",
        "numeric_cols = [\"procedure_area\", \"has_parking\", \"year\", \"month\", \"dow\"]\n",
        "cat_cols = [\"area_name_en\", \"nearest_metro_en\", \"nearest_mall_en\", \"nearest_landmark_en\",\n",
        "            \"property_type_en\", \"rooms_en\"]\n",
        "\n",
        "needed_cols = [label_col] + numeric_cols + cat_cols\n",
        "\n",
        "# Keep only needed columns\n",
        "df_reg = df2.select(needed_cols)\n",
        "\n",
        "\n",
        "df_reg = (\n",
        "    df_reg\n",
        "    .filter(F.col(label_col) > 0)\n",
        "    .filter(F.col(\"procedure_area\") > 0)\n",
        ")\n",
        "\n",
        "# Fill missing categoricals with \"unknown\"\n",
        "fill_map = {c: \"unknown\" for c in cat_cols}\n",
        "df_reg = df_reg.fillna(fill_map)\n",
        "\n",
        "# Fill missing has_parking with 0\n",
        "df_reg = df_reg.fillna({\"has_parking\": 0})\n",
        "\n",
        "print(\"Rows before:\", df2.count())\n",
        "print(\"Rows after :\", df_reg.count())\n",
        "\n",
        "df_reg.select(label_col, \"procedure_area\", \"area_name_en\", \"nearest_metro_en\", \"nearest_mall_en\").show(5, truncate=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPaKZFJAbwXs",
        "outputId": "c50b99d5-52bd-4fe2-a5a2-db2910efc266"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows before: 30173\n",
            "Rows after : 30173\n",
            "+----------------+--------------+------------------+--------------------------+------------------+\n",
            "|meter_sale_price|procedure_area|area_name_en      |nearest_metro_en          |nearest_mall_en   |\n",
            "+----------------+--------------+------------------+--------------------------+------------------+\n",
            "|5711.51         |151.8         |Burj Khalifa      |Business Bay Metro Station|Dubai Mall        |\n",
            "|2653.16         |76.0          |Al Warsan First   |Rashidiya Metro Station   |City Centre Mirdif|\n",
            "|3142.93         |356.3         |Al Thanayah Fourth|Nakheel Metro Station     |Marina Mall       |\n",
            "|3653.13         |159.3         |Al Goze Fourth    |Noor Bank Metro Station   |Dubai Mall        |\n",
            "|1772.12         |531.29        |Al Thanayah Fourth|Nakheel Metro Station     |Marina Mall       |\n",
            "+----------------+--------------+------------------+--------------------------+------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "distinct_counts = df_reg.agg(\n",
        "    *[F.countDistinct(c).alias(c) for c in cat_cols]\n",
        ").collect()[0].asDict()\n",
        "\n",
        "distinct_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srts9x9KQ4ii",
        "outputId": "3600422a-2f04-4240-9db1-581c4fbfdee2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'area_name_en': 67,\n",
              " 'nearest_metro_en': 38,\n",
              " 'nearest_mall_en': 6,\n",
              " 'nearest_landmark_en': 14,\n",
              " 'property_type_en': 2,\n",
              " 'rooms_en': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_reg.select([label_col] + feature_cols).describe().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07c1jMw0bwUQ",
        "outputId": "75e0ef56-2bfc-4fb7-abc0-3deed3d62ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+------------------+------------------+------------------+\n",
            "|summary|      actual_worth|    procedure_area|  meter_sale_price|  meter_rent_price|        rent_value|\n",
            "+-------+------------------+------------------+------------------+------------------+------------------+\n",
            "|  count|             30173|             30173|             30173|             30173|             30173|\n",
            "|   mean|1141369.1333311237|146.69104928247128|23615.968940774856|23615.968940774856|1141369.1630288672|\n",
            "| stddev|1179763.9031765272|247.93351448611162|  312756.464488263|  312756.464488263| 1179763.895927969|\n",
            "|    min|               2.0|              0.09|              0.01|              0.01|               2.0|\n",
            "|    max|           3.744E7|           35703.0|     1.109415556E7|     1.109415556E7|           3.744E7|\n",
            "+-------+------------------+------------------+------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression"
      ],
      "metadata": {
        "id": "AM8Q_3yHdCyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "\n",
        "\n",
        "label_col = \"meter_sale_price\"\n",
        "\n",
        "numeric_cols = [\"procedure_area\", \"has_parking\", \"year\", \"month\", \"dow\"]\n",
        "cat_cols = [\"area_name_en\", \"nearest_metro_en\", \"nearest_mall_en\",\n",
        "            \"nearest_landmark_en\", \"property_type_en\", \"rooms_en\"]\n",
        "\n",
        "# Index categorical columns\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"keep\")\n",
        "    for c in cat_cols\n",
        "]\n",
        "\n",
        "# OneHot encode them\n",
        "encoder = OneHotEncoder(\n",
        "    inputCols=[f\"{c}_idx\" for c in cat_cols],\n",
        "    outputCols=[f\"{c}_ohe\" for c in cat_cols],\n",
        "    handleInvalid=\"keep\"\n",
        ")\n",
        "\n",
        "# Assemble everything into feature vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=numeric_cols + [f\"{c}_ohe\" for c in cat_cols],\n",
        "    outputCol=\"features_raw\"\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler(\n",
        "    inputCol=\"features_raw\",\n",
        "    outputCol=\"features\",\n",
        "    withMean=True,\n",
        "    withStd=True\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "Y7-5mfk3bwR6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Numeric columns:\", numeric_cols)\n",
        "print(\"Categorical columns:\", cat_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg_7vmwCR0Wn",
        "outputId": "cc6e05fd-05f5-4b3e-9542-bbd25de633a9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric columns: ['procedure_area', 'has_parking', 'year', 'month', 'dow']\n",
            "Categorical columns: ['area_name_en', 'nearest_metro_en', 'nearest_mall_en', 'nearest_landmark_en', 'property_type_en', 'rooms_en']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = df_reg.randomSplit([0.8, 0.2], seed=42)\n",
        "print(\"Train:\", train_df.count(), \"Test:\", test_df.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LATfRbwdQC3",
        "outputId": "8228277f-f048-42d8-923e-71632bfaf7a6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 24263 Test: 5910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1 — Linear Regression (Baseline)"
      ],
      "metadata": {
        "id": "vBFpvH1jd3Fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=label_col)\n",
        "\n",
        "pipe_lr = Pipeline(stages=indexers + [encoder, assembler, scaler, lr])\n",
        "model_lr = pipe_lr.fit(train_df)\n",
        "\n",
        "pred_lr = model_lr.transform(test_df)\n",
        "\n",
        "rmse_eval = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "mae_eval  = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"mae\")\n",
        "r2_eval   = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"r2\")\n",
        "\n",
        "rmse = rmse_eval.evaluate(pred_lr)\n",
        "mae  = mae_eval.evaluate(pred_lr)\n",
        "r2   = r2_eval.evaluate(pred_lr)\n",
        "\n",
        "print(f\"Linear Regression -> RMSE={rmse:.2f} | MAE={mae:.2f} | R2={r2:.4f}\")\n",
        "\n",
        "pred_lr.select(label_col, \"prediction\", \"procedure_area\", \"area_name_en\", \"nearest_metro_en\").show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JRAvTgDdP_a",
        "outputId": "b5050bf2-d440-42b5-b95d-0ca75baa8ce5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression -> RMSE=312022.94 | MAE=39021.79 | R2=0.0718\n",
            "+----------------+-------------------+--------------+------------------+---------------------+\n",
            "|meter_sale_price|prediction         |procedure_area|area_name_en      |nearest_metro_en     |\n",
            "+----------------+-------------------+--------------+------------------+---------------------+\n",
            "|269.87          |7426.639402468827  |100.17        |Wadi Al Safa 5    |unknown              |\n",
            "|504.98          |14747.630820691698 |1221.39       |Al Thanayah Fourth|Nakheel Metro Station|\n",
            "|542.9           |20913.540456783925 |745.11        |Wadi Al Safa 6    |unknown              |\n",
            "|705.64          |-418.66789067323043|510.02        |Al Thanayah Fourth|Nakheel Metro Station|\n",
            "|826.4           |-12711.041559556612|291.56        |Al Thanayah Fourth|Damac Properties     |\n",
            "+----------------+-------------------+--------------+------------------+---------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2 — Decision Tree Regression"
      ],
      "metadata": {
        "id": "-U_mzeXYeLi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "\n",
        "dt = DecisionTreeRegressor(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=label_col,\n",
        "    maxDepth=8,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "pipe_dt = Pipeline(stages=indexers + [encoder, assembler, scaler, dt])\n",
        "model_dt = pipe_dt.fit(train_df)\n",
        "\n",
        "pred_dt = model_dt.transform(test_df)\n",
        "\n",
        "rmse_dt = rmse_eval.evaluate(pred_dt)\n",
        "mae_dt  = mae_eval.evaluate(pred_dt)\n",
        "r2_dt   = r2_eval.evaluate(pred_dt)\n",
        "\n",
        "print(f\"Decision Tree -> RMSE={rmse_dt:.2f} | MAE={mae_dt:.2f} | R2={r2_dt:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54si6qYVd2tM",
        "outputId": "7bf16b7e-5a54-46d9-ade9-b0110a6a172c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree -> RMSE=46401.15 | MAE=4516.09 | R2=0.9752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model validation analysis"
      ],
      "metadata": {
        "id": "3qkiGSkwYvvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col_name in [\"procedure_area\", \"has_parking\", \"year\", \"month\", \"dow\"]:\n",
        "    corr = df_reg.stat.corr(\"meter_sale_price\", col_name)\n",
        "    print(col_name, \"correlation:\", corr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWaexPKeUpYq",
        "outputId": "c99fd665-2eae-4d62-c9be-caf58ce959da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "procedure_area correlation: -0.02995711800116248\n",
            "has_parking correlation: 0.0322662890722229\n",
            "year correlation: -0.007808566018858272\n",
            "month correlation: 0.0035404670020437244\n",
            "dow correlation: 0.04151403601482728\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Linear relationships are weak thats why LR underperformed\")"
      ],
      "metadata": {
        "id": "DdiDctpWZbrg",
        "outputId": "5456f54a-cc2c-43c4-eee2-c75d06e004c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear relationships are weak thats why LR underperformed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train R2:\")\n",
        "pred_train_dt = model_dt.transform(train_df)\n",
        "print(r2_eval.evaluate(pred_train_dt))\n",
        "\n",
        "print(\"Test R2:\")\n",
        "print(r2_dt)"
      ],
      "metadata": {
        "id": "q_2xaET2WYRx",
        "outputId": "b5f09fd7-c2a0-423b-8579-3fe4951c1db8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train R2:\n",
            "0.9673378224704848\n",
            "Test R2:\n",
            "0.9752170423070973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Results show that there is no major overfitting and the tree has generalized well\")"
      ],
      "metadata": {
        "id": "i6bUxs_UZpk0",
        "outputId": "5fbd779b-ed9d-4336-ba34-fc7519200606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results show that there is no major overfitting and the tree has generalized well\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3 — RandomForest"
      ],
      "metadata": {
        "id": "B8QphtIsXB0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=label_col,\n",
        "    numTrees=80,\n",
        "    maxDepth=10,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "pipe_rf = Pipeline(stages=indexers + [encoder, assembler, scaler, rf])\n",
        "model_rf = pipe_rf.fit(train_df)\n",
        "\n",
        "pred_rf = model_rf.transform(test_df)\n",
        "\n",
        "rmse_rf = rmse_eval.evaluate(pred_rf)\n",
        "mae_rf  = mae_eval.evaluate(pred_rf)\n",
        "r2_rf   = r2_eval.evaluate(pred_rf)\n",
        "\n",
        "print(f\"Random Forest -> RMSE={rmse_rf:.2f} | MAE={mae_rf:.2f} | R2={r2_rf:.4f}\")"
      ],
      "metadata": {
        "id": "TaxyySe-XTLe",
        "outputId": "0451f3fb-9a70-424c-d47d-0f8bc7d58706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest -> RMSE=60476.18 | MAE=5274.38 | R2=0.9579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lr.select(label_col, \"prediction\").show(5)\n",
        "pred_dt.select(label_col, \"prediction\").show(5)\n",
        "pred_rf.select(label_col, \"prediction\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbtD_iX0d2ps",
        "outputId": "06df6b21-9e9f-4508-83d8-1ca0dc835615"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------------+\n",
            "|meter_sale_price|        prediction|\n",
            "+----------------+------------------+\n",
            "|          269.87| 9243.638326830094|\n",
            "|          504.98|14904.701441339304|\n",
            "|           542.9| 22742.49060550967|\n",
            "|          705.64|-2644.498810199646|\n",
            "|           826.4|-12305.77194216656|\n",
            "+----------------+------------------+\n",
            "only showing top 5 rows\n",
            "+----------------+------------------+\n",
            "|meter_sale_price|        prediction|\n",
            "+----------------+------------------+\n",
            "|          269.87| 7102.361569839303|\n",
            "|          504.98|1189.8238775510204|\n",
            "|           542.9| 4496.628507614214|\n",
            "|          705.64|1189.8238775510204|\n",
            "|           826.4| 4496.628507614214|\n",
            "+----------------+------------------+\n",
            "only showing top 5 rows\n",
            "+----------------+------------------+\n",
            "|meter_sale_price|        prediction|\n",
            "+----------------+------------------+\n",
            "|          269.87|  7358.08245858437|\n",
            "|          504.98|1507.9412685841676|\n",
            "|           542.9|2833.8639049063822|\n",
            "|          705.64|1532.4497563675477|\n",
            "|           826.4|3987.7634119714967|\n",
            "+----------------+------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual CV - Decision Tree\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qAuMmINZbXO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import rand, floor\n",
        "\n",
        "k = 10\n",
        "\n",
        "df_cv = df_reg.withColumn(\"fold\", floor(rand(seed=42) * k))\n",
        "\n",
        "df_cv.groupBy(\"fold\").count().show()"
      ],
      "metadata": {
        "id": "CNQoz4Pfbr7R",
        "outputId": "7c9d6766-d857-4984-b2b9-6237584d058b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|fold|count|\n",
            "+----+-----+\n",
            "|   0| 3002|\n",
            "|   7| 2993|\n",
            "|   6| 2994|\n",
            "|   9| 2943|\n",
            "|   5| 3094|\n",
            "|   1| 3090|\n",
            "|   3| 3021|\n",
            "|   8| 2966|\n",
            "|   2| 2991|\n",
            "|   4| 3079|\n",
            "+----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "dt = DecisionTreeRegressor(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=label_col,\n",
        "    maxDepth=8,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "rmse_scores = []\n",
        "\n",
        "for fold in range(k):\n",
        "\n",
        "    train_fold = df_cv.filter(df_cv.fold != fold)\n",
        "    val_fold   = df_cv.filter(df_cv.fold == fold)\n",
        "\n",
        "    pipe = Pipeline(stages=indexers + [encoder, assembler, scaler, dt])\n",
        "    model = pipe.fit(train_fold)\n",
        "\n",
        "    preds = model.transform(val_fold)\n",
        "\n",
        "    rmse = rmse_eval.evaluate(preds)\n",
        "    rmse_scores.append(rmse)\n",
        "\n",
        "    print(f\"Fold {fold} RMSE: {rmse:.2f}\")\n",
        "\n",
        "print(\"Average RMSE:\", sum(rmse_scores)/len(rmse_scores))"
      ],
      "metadata": {
        "id": "Mjm4Ak4_cTZG",
        "outputId": "2c79e60d-7ce8-401d-a1bd-62938c9b1a60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 0 RMSE: 97344.78\n",
            "Fold 1 RMSE: 72279.84\n",
            "Fold 2 RMSE: 42622.77\n",
            "Fold 3 RMSE: 63379.59\n",
            "Fold 4 RMSE: 46065.45\n",
            "Fold 5 RMSE: 130338.69\n",
            "Fold 6 RMSE: 106253.32\n",
            "Fold 7 RMSE: 69548.84\n",
            "Fold 8 RMSE: 45471.73\n",
            "Fold 9 RMSE: 35521.25\n",
            "Average RMSE: 70882.62500737255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual CV - Linear Regression\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "08jVU1DtfvYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=label_col)\n",
        "\n",
        "rmse_lr_scores = []\n",
        "\n",
        "for fold in range(k):\n",
        "\n",
        "    train_fold = df_cv.filter(df_cv.fold != fold)\n",
        "    val_fold   = df_cv.filter(df_cv.fold == fold)\n",
        "\n",
        "    pipe = Pipeline(stages=indexers + [encoder, assembler, scaler, lr])\n",
        "    model = pipe.fit(train_fold)\n",
        "\n",
        "    preds = model.transform(val_fold)\n",
        "\n",
        "    rmse = rmse_eval.evaluate(preds)\n",
        "    rmse_lr_scores.append(rmse)\n",
        "\n",
        "    print(f\"LR Fold {fold} RMSE: {rmse:.2f}\")\n",
        "\n",
        "print(\"LR Average RMSE:\", sum(rmse_lr_scores)/len(rmse_lr_scores))"
      ],
      "metadata": {
        "id": "igazAZsNf11V",
        "outputId": "05e4447c-b6c5-4b27-9adc-be706e189af7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR Fold 0 RMSE: 363372.92\n",
            "LR Fold 1 RMSE: 291450.90\n",
            "LR Fold 2 RMSE: 219404.82\n",
            "LR Fold 3 RMSE: 240988.19\n",
            "LR Fold 4 RMSE: 277320.30\n",
            "LR Fold 5 RMSE: 393575.98\n",
            "LR Fold 6 RMSE: 307362.43\n",
            "LR Fold 7 RMSE: 319428.61\n",
            "LR Fold 8 RMSE: 295188.42\n",
            "LR Fold 9 RMSE: 284194.93\n",
            "LR Average RMSE: 299228.75058844744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual CV - Random Forest\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "68intDEZjR94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=label_col,\n",
        "    numTrees=80,\n",
        "    maxDepth=10,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "rmse_rf_scores = []\n",
        "\n",
        "for fold in range(k):\n",
        "\n",
        "    train_fold = df_cv.filter(df_cv.fold != fold)\n",
        "    val_fold   = df_cv.filter(df_cv.fold == fold)\n",
        "\n",
        "    pipe = Pipeline(stages=indexers + [encoder, assembler, scaler, rf])\n",
        "    model = pipe.fit(train_fold)\n",
        "\n",
        "    preds = model.transform(val_fold)\n",
        "\n",
        "    rmse = rmse_eval.evaluate(preds)\n",
        "    rmse_rf_scores.append(rmse)\n",
        "\n",
        "    print(f\"RF Fold {fold} RMSE: {rmse:.2f}\")\n",
        "\n",
        "print(\"RF Average RMSE:\", sum(rmse_rf_scores)/len(rmse_rf_scores))"
      ],
      "metadata": {
        "id": "Px-kcyLAjZnD",
        "outputId": "017a368c-1510-4382-b8c9-b36f0d98e242",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Fold 0 RMSE: 110616.69\n",
            "RF Fold 1 RMSE: 61092.23\n",
            "RF Fold 2 RMSE: 39061.14\n",
            "RF Fold 3 RMSE: 59328.53\n",
            "RF Fold 4 RMSE: 56953.88\n",
            "RF Fold 5 RMSE: 103381.31\n",
            "RF Fold 6 RMSE: 71604.58\n",
            "RF Fold 7 RMSE: 79516.04\n",
            "RF Fold 8 RMSE: 44461.33\n",
            "RF Fold 9 RMSE: 45151.51\n",
            "RF Average RMSE: 67116.7241819336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Model\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Hse4ujsyniD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "\n",
        "train_df = train_df.withColumn(\"row_id\", monotonically_increasing_id())\n",
        "test_df  = test_df.withColumn(\"row_id\", monotonically_increasing_id())"
      ],
      "metadata": {
        "id": "Hw1qeIq_sr6d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "B = 10\n",
        "\n",
        "dt_base = DecisionTreeRegressor(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=label_col,\n",
        "    maxDepth=8,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "pred_list = []\n",
        "\n",
        "for b in range(B):\n",
        "    boot_train = train_df.sample(withReplacement=True, fraction=1.0, seed=100 + b)\n",
        "\n",
        "    pipe = Pipeline(stages=indexers + [encoder, assembler, scaler, dt_base])\n",
        "    model = pipe.fit(boot_train)\n",
        "\n",
        "    preds = model.transform(test_df).select(\n",
        "        \"row_id\",\n",
        "        F.col(\"prediction\").alias(f\"pred_{b}\")\n",
        "    )\n",
        "\n",
        "    pred_list.append(preds)\n",
        "    print(f\"Bag model {b+1}/{B} done\")"
      ],
      "metadata": {
        "id": "YprnXtazn5KM",
        "outputId": "7aae1fd6-e78b-4e0a-c129-ef5463ef2737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag model 1/10 done\n",
            "Bag model 2/10 done\n",
            "Bag model 3/10 done\n",
            "Bag model 4/10 done\n",
            "Bag model 5/10 done\n",
            "Bag model 6/10 done\n",
            "Bag model 7/10 done\n",
            "Bag model 8/10 done\n",
            "Bag model 9/10 done\n",
            "Bag model 10/10 done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# join all prediction columns by row_id\n",
        "bagged = pred_list[0]\n",
        "for i in range(1, B):\n",
        "    bagged = bagged.join(pred_list[i], on=\"row_id\", how=\"inner\")\n",
        "\n",
        "# bring true label from test_df\n",
        "bagged = bagged.join(test_df.select(\"row_id\", label_col), on=\"row_id\", how=\"inner\")\n",
        "\n",
        "# average predictions\n",
        "pred_cols = [F.col(f\"pred_{i}\") for i in range(B)]\n",
        "bagged = bagged.withColumn(\"prediction\", sum(pred_cols) / F.lit(B))\n",
        "\n",
        "# evaluate\n",
        "rmse_bag = rmse_eval.evaluate(bagged)\n",
        "mae_bag  = mae_eval.evaluate(bagged)\n",
        "r2_bag   = r2_eval.evaluate(bagged)\n",
        "\n",
        "print(f\"Bagging -> RMSE={rmse_bag:.2f} | MAE={mae_bag:.2f} | R2={r2_bag:.4f}\")"
      ],
      "metadata": {
        "id": "BPvErsr2rlLS",
        "outputId": "1c62c9a4-5fb1-464f-8eb8-a3e8b33a5400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging -> RMSE=44032.79 | MAE=4191.56 | R2=0.9815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree Regression significantly outperformed Linear Regression across all metrics and was therefore selected as the final regression model"
      ],
      "metadata": {
        "id": "JAq_TGC2im5Z"
      }
    }
  ]
}