{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Ensemble Learning from Scratch\n",
        "\n",
        "This notebook implements a custom ensemble learning approach using\n",
        "bagging (bootstrap aggregating) built explicitly from first principles.\n",
        "\n",
        "Rather than relying on Spark’s built-in ensemble models, the ensemble\n",
        "logic—including data resampling, model training, and prediction\n",
        "aggregation—is implemented manually to ensure transparency and\n",
        "methodological clarity."
      ],
      "metadata": {
        "id": "_glDAuFUe7tW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"DLD_Custom_Ensemble\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "ul0Ivs9te-6R"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ml = spark.read.parquet(\n",
        "    \"land_transactions_features.parquet\"\n",
        ")"
      ],
      "metadata": {
        "id": "fF2h6_G1fAH4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test Split for Ensemble Evaluation\n",
        "\n",
        "A simple train/test split is used to compare ensemble performance against\n",
        "single-model baselines. Robust evaluation is handled separately via\n",
        "manual cross-validation."
      ],
      "metadata": {
        "id": "1X3LEs6affj6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "niInNunDe6lF"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = df_ml.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Learner Selection\n",
        "\n",
        "Decision Tree Regressors are used as base learners due to their ability\n",
        "to capture non-linear relationships and their sensitivity to training\n",
        "data variation, which makes them well-suited for bagging."
      ],
      "metadata": {
        "id": "Ag9AtquSfiMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "\n",
        "def train_base_model(train_data, seed):\n",
        "    return DecisionTreeRegressor(\n",
        "        featuresCol=\"scaled_features\",\n",
        "        labelCol=\"meter_sale_price\",\n",
        "        maxDepth=5,\n",
        "        seed=seed\n",
        "    ).fit(train_data)"
      ],
      "metadata": {
        "id": "Af0_EapKfiAb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bootstrap Sampling\n",
        "\n",
        "Bootstrap sampling is performed by sampling the training data with\n",
        "replacement. Each base learner is trained on a different bootstrap\n",
        "sample to promote diversity within the ensemble."
      ],
      "metadata": {
        "id": "vD00WiTTflZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_sample(df, seed):\n",
        "    return df.sample(\n",
        "        withReplacement=True,\n",
        "        fraction=1.0,\n",
        "        seed=seed\n",
        "    )"
      ],
      "metadata": {
        "id": "Al3LP-F3flMV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Ensemble\n",
        "\n",
        "Multiple base models are trained independently on different bootstrap\n",
        "samples of the training data."
      ],
      "metadata": {
        "id": "xTr46SJ5foeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_models = 5\n",
        "ensemble_models = []\n",
        "\n",
        "for i in range(num_models):\n",
        "    print(f\"Training base model {i+1}\")\n",
        "\n",
        "    sample_df = bootstrap_sample(train_df, seed=42 + i)\n",
        "    model = train_base_model(sample_df, seed=100 + i)\n",
        "\n",
        "    ensemble_models.append(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4gfYBgYfe_U",
        "outputId": "33d23254-893e-4d30-f329-56b35054be90"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training base model 1\n",
            "Training base model 2\n",
            "Training base model 3\n",
            "Training base model 4\n",
            "Training base model 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Prediction Aggregation\n",
        "\n",
        "Predictions from all base learners are aggregated by averaging, producing\n",
        "the final ensemble prediction."
      ],
      "metadata": {
        "id": "rVdJmaJvhBCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "ensemble_pred_df = test_df\n",
        "\n",
        "for i, model in enumerate(ensemble_models):\n",
        "    ensemble_pred_df = (\n",
        "        model\n",
        "        .transform(ensemble_pred_df)\n",
        "        .withColumnRenamed(\"prediction\", f\"pred_{i}\")\n",
        "    )\n",
        "\n",
        "# Manually average predictions\n",
        "avg_expr = \" + \".join([f\"pred_{i}\" for i in range(num_models)])\n",
        "\n",
        "ensemble_pred_df = ensemble_pred_df.withColumn(\n",
        "    \"ensemble_prediction\",\n",
        "    expr(f\"({avg_expr}) / {num_models}\")\n",
        ")"
      ],
      "metadata": {
        "id": "NDsoBYXChvZm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Performance Evaluation\n",
        "\n",
        "The ensemble model is evaluated using the same metric applied to\n",
        "individual base learners to enable fair comparison."
      ],
      "metadata": {
        "id": "6AEA5a5Wh65k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"meter_sale_price\",\n",
        "    predictionCol=\"ensemble_prediction\",\n",
        "    metricName=\"rmse\"\n",
        ")\n",
        "\n",
        "rmse_ensemble = evaluator.evaluate(ensemble_pred_df)\n",
        "\n",
        "print(\"Ensemble RMSE:\", rmse_ensemble)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deqkgWp0h7-i",
        "outputId": "7fd34687-02dd-492a-be90-7e783c4326a5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble RMSE: 114973.98927169091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "single_model = train_base_model(train_df, seed=999)\n",
        "single_preds = single_model.transform(test_df)\n",
        "\n",
        "rmse_single = evaluator.evaluate(\n",
        "    single_preds.withColumnRenamed(\"prediction\", \"ensemble_prediction\")\n",
        ")\n",
        "\n",
        "print(\"Single Model RMSE:\", rmse_single)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBHGaacJh983",
        "outputId": "859fc102-b02f-4e68-f22b-769a0dfe9226"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Model RMSE: 116741.20271981947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Learning Summary\n",
        "\n",
        "The custom bagging ensemble demonstrates how combining multiple\n",
        "independently trained models can improve prediction robustness compared\n",
        "to a single base learner.\n",
        "\n",
        "This ensemble is implemented entirely from scratch, including bootstrap\n",
        "sampling and prediction aggregation, and serves as a practical\n",
        "demonstration of ensemble learning principles in a large-scale Spark\n",
        "environment."
      ],
      "metadata": {
        "id": "q-v8l4mJf1Cq"
      }
    }
  ]
}