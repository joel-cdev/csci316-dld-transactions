{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Ensemble Learning from Scratch\n",
        "\n",
        "This notebook implements a custom ensemble learning approach using\n",
        "bagging (bootstrap aggregating) built explicitly from first principles.\n",
        "\n",
        "Rather than relying on Spark’s built-in ensemble models, the ensemble\n",
        "logic—including data resampling, model training, and prediction\n",
        "aggregation—is implemented manually to ensure transparency and\n",
        "methodological clarity."
      ],
      "metadata": {
        "id": "H5XDvtRY6n_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"DLD_Custom_Ensemble\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "ul0Ivs9te-6R"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ml = spark.read.parquet(\n",
        "    \"land_transaction_features.parquet\"\n",
        ")"
      ],
      "metadata": {
        "id": "fF2h6_G1fAH4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test Split for Ensemble Evaluation\n",
        "\n",
        "A simple train/test split is used to compare ensemble performance against\n",
        "single-model baselines. Robust evaluation is handled separately via\n",
        "manual cross-validation."
      ],
      "metadata": {
        "id": "1X3LEs6affj6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "niInNunDe6lF"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = df_ml.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Learner Selection\n",
        "\n",
        "Decision Tree Regressors are used as base learners due to their ability\n",
        "to capture non-linear relationships and their sensitivity to training\n",
        "data variation, which makes them well-suited for bagging."
      ],
      "metadata": {
        "id": "Ag9AtquSfiMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "\n",
        "def train_base_model(train_data, seed):\n",
        "    return DecisionTreeRegressor(\n",
        "        featuresCol=\"scaled_features\",\n",
        "        labelCol=\"meter_sale_price\",\n",
        "        maxDepth=5,\n",
        "        seed=seed\n",
        "    ).fit(train_data)"
      ],
      "metadata": {
        "id": "Af0_EapKfiAb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bootstrap Sampling\n",
        "\n",
        "Bootstrap sampling is performed by sampling the training data with\n",
        "replacement. Each base learner is trained on a different bootstrap\n",
        "sample to promote diversity within the ensemble."
      ],
      "metadata": {
        "id": "vD00WiTTflZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bootstrap_sample(df, seed):\n",
        "    return df.sample(\n",
        "        withReplacement=True,\n",
        "        fraction=1.0,\n",
        "        seed=seed\n",
        "    )"
      ],
      "metadata": {
        "id": "Al3LP-F3flMV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Ensemble\n",
        "\n",
        "Multiple base models are trained independently on different bootstrap\n",
        "samples of the training data."
      ],
      "metadata": {
        "id": "xTr46SJ5foeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_models = 5\n",
        "ensemble_models = []\n",
        "\n",
        "for i in range(num_models):\n",
        "    print(f\"Training base model {i+1}\")\n",
        "\n",
        "    sample_df = bootstrap_sample(train_df, seed=42 + i)\n",
        "    model = train_base_model(sample_df, seed=100 + i)\n",
        "\n",
        "    ensemble_models.append(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4gfYBgYfe_U",
        "outputId": "efe89039-3848-4923-b6ea-6c40d1408c88"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training base model 1\n",
            "Training base model 2\n",
            "Training base model 3\n",
            "Training base model 4\n",
            "Training base model 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Prediction Aggregation\n",
        "\n",
        "Predictions from all base learners are aggregated by averaging, producing\n",
        "the final ensemble prediction."
      ],
      "metadata": {
        "id": "rVdJmaJvhBCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "ensemble_pred_df = test_df\n",
        "\n",
        "for i, model in enumerate(ensemble_models):\n",
        "    ensemble_pred_df = (\n",
        "        model\n",
        "        .transform(ensemble_pred_df)\n",
        "        .withColumnRenamed(\"prediction\", f\"pred_{i}\")\n",
        "    )\n",
        "\n",
        "# Manually average predictions\n",
        "avg_expr = \" + \".join([f\"pred_{i}\" for i in range(num_models)])\n",
        "\n",
        "ensemble_pred_df = ensemble_pred_df.withColumn(\n",
        "    \"ensemble_prediction\",\n",
        "    expr(f\"({avg_expr}) / {num_models}\")\n",
        ")"
      ],
      "metadata": {
        "id": "NDsoBYXChvZm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Performance Evaluation\n",
        "\n",
        "The ensemble model is evaluated using the same metric applied to\n",
        "individual base learners to enable fair comparison."
      ],
      "metadata": {
        "id": "6AEA5a5Wh65k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"meter_sale_price\",\n",
        "    predictionCol=\"ensemble_prediction\",\n",
        "    metricName=\"rmse\"\n",
        ")\n",
        "\n",
        "rmse_ensemble = evaluator.evaluate(ensemble_pred_df)\n",
        "\n",
        "print(\"Ensemble RMSE:\", rmse_ensemble)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deqkgWp0h7-i",
        "outputId": "27a5d010-3bca-45d0-f5f1-b2c1a2ea161b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble RMSE: 114973.98927169091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "single_model = train_base_model(train_df, seed=999)\n",
        "single_preds = single_model.transform(test_df)\n",
        "\n",
        "rmse_single = evaluator.evaluate(\n",
        "    single_preds.withColumnRenamed(\"prediction\", \"ensemble_prediction\")\n",
        ")\n",
        "\n",
        "print(\"Single Model RMSE:\", rmse_single)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBHGaacJh983",
        "outputId": "be468e6a-170b-416f-9354-26883a4bbb17"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Model RMSE: 116741.20271981947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble Learning Summary\n",
        "\n",
        "The custom bagging ensemble demonstrates how combining multiple\n",
        "independently trained models can improve prediction robustness compared\n",
        "to a single base learner.\n",
        "\n",
        "This ensemble is implemented entirely from scratch, including bootstrap\n",
        "sampling and prediction aggregation, and serves as a practical\n",
        "demonstration of ensemble learning principles in a large-scale Spark\n",
        "environment."
      ],
      "metadata": {
        "id": "q-v8l4mJf1Cq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAWcJFN-6amE"
      },
      "source": [
        "## Linear Regression Bagging & Boosting\n",
        "\n",
        "This section adds:\n",
        "- a **baseline Linear Regression** model,\n",
        "- **bagging** (bootstrap aggregation) using Linear Regression as the base learner,\n",
        "- **boosting** (tree-based boosting in Spark + an optional Linear-Regression-based AdaBoost in scikit-learn for comparison).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCTIWJlF6amE",
        "outputId": "2a762bac-f714-4e87-c41e-13ec48fe457c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------------+\n",
            "|meter_sale_price|        prediction|\n",
            "+----------------+------------------+\n",
            "|          110.96|34786.054928781385|\n",
            "|          269.87|30251.387451888546|\n",
            "|          342.69|-30302.29827854948|\n",
            "|          477.36| 28271.38382512618|\n",
            "|           542.9|-33993.96497656226|\n",
            "+----------------+------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "# Baseline: Linear Regression (Spark ML)\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "lr = LinearRegression(\n",
        "    featuresCol=\"scaled_features\",\n",
        "    labelCol=\"meter_sale_price\",\n",
        "    maxIter=100,\n",
        "    regParam=0.0,\n",
        "    elasticNetParam=0.0\n",
        ")\n",
        "\n",
        "lr_model = lr.fit(train_df)\n",
        "\n",
        "lr_pred = lr_model.transform(test_df)\n",
        "lr_pred.select(\"meter_sale_price\", \"prediction\").show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuhIhJHp6amE",
        "outputId": "a4c23ff7-4d3d-4729-f3b9-2528e33aa4c0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression -> RMSE: 1286960.9215, MAE: 63187.5461, R2: -16.3713\n"
          ]
        }
      ],
      "source": [
        "#evaluate Linear regression\n",
        "\n",
        "evaluator_rmse = RegressionEvaluator(\n",
        "    labelCol=\"meter_sale_price\", predictionCol=\"prediction\", metricName=\"rmse\"\n",
        ")\n",
        "evaluator_r2 = RegressionEvaluator(\n",
        "    labelCol=\"meter_sale_price\", predictionCol=\"prediction\", metricName=\"r2\"\n",
        ")\n",
        "evaluator_mae = RegressionEvaluator(\n",
        "    labelCol=\"meter_sale_price\", predictionCol=\"prediction\", metricName=\"mae\"\n",
        ")\n",
        "\n",
        "lr_rmse = evaluator_rmse.evaluate(lr_pred)\n",
        "lr_r2 = evaluator_r2.evaluate(lr_pred)\n",
        "lr_mae = evaluator_mae.evaluate(lr_pred)\n",
        "\n",
        "print(f\"Linear Regression -> RMSE: {lr_rmse:.4f}, MAE: {lr_mae:.4f}, R2: {lr_r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkfqVggt6amE"
      },
      "source": [
        "## Bagging with Linear Regression (Bootstrap Aggregation)\n",
        "\n",
        "We train multiple Linear Regression models on bootstrap samples of the training set and **average** their predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70Z8whGe6amE",
        "outputId": "83dde78e-d5b9-4c15-f3ae-e0a2fe22cd09"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training LR bagging model 1/10\n",
            "Training LR bagging model 2/10\n",
            "Training LR bagging model 3/10\n",
            "Training LR bagging model 4/10\n",
            "Training LR bagging model 5/10\n",
            "Training LR bagging model 6/10\n",
            "Training LR bagging model 7/10\n",
            "Training LR bagging model 8/10\n",
            "Training LR bagging model 9/10\n",
            "Training LR bagging model 10/10\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "def train_lr_base_model(train_data):\n",
        "    return LinearRegression(\n",
        "        featuresCol=\"scaled_features\",\n",
        "        labelCol=\"meter_sale_price\",\n",
        "        maxIter=100,\n",
        "        regParam=0.0,\n",
        "        elasticNetParam=0.0\n",
        "    ).fit(train_data)\n",
        "\n",
        "num_lr_models = 10\n",
        "lr_ensemble_models = []\n",
        "\n",
        "for i in range(num_lr_models):\n",
        "    print(f\"Training LR bagging model {i+1}/{num_lr_models}\")\n",
        "    sample_df = bootstrap_sample(train_df, seed=900 + i)\n",
        "    lr_ensemble_models.append(train_lr_base_model(sample_df))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2Uvuw2o6amE",
        "outputId": "30be5615-c38c-4f08-f757-58abf2881af9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+---------------------+\n",
            "|meter_sale_price|lr_bagging_prediction|\n",
            "+----------------+---------------------+\n",
            "|          110.96| 1.669437254714057...|\n",
            "|          269.87| 1.562890953849067...|\n",
            "|          342.69| -1.27305689174912...|\n",
            "|          477.36| 1.516368893773190...|\n",
            "|           542.9| -1.11753466628267...|\n",
            "+----------------+---------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ],
      "source": [
        "#aggregate bagged LR predictions by averaging\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "lr_ensemble_pred_df = test_df\n",
        "\n",
        "for i, model in enumerate(lr_ensemble_models):\n",
        "    lr_ensemble_pred_df = (\n",
        "        model\n",
        "        .transform(lr_ensemble_pred_df)\n",
        "        .withColumnRenamed(\"prediction\", f\"lr_pred_{i}\")\n",
        "    )\n",
        "\n",
        "avg_expr = \" + \".join([f\"lr_pred_{i}\" for i in range(num_lr_models)])\n",
        "\n",
        "lr_ensemble_pred_df = lr_ensemble_pred_df.withColumn(\n",
        "    \"lr_bagging_prediction\",\n",
        "    expr(f\"({avg_expr}) / {num_lr_models}\")\n",
        ")\n",
        "\n",
        "lr_ensemble_pred_df.select(\"meter_sale_price\", \"lr_bagging_prediction\").show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzP8pnTU6amE",
        "outputId": "63782288-2464-4d5f-c3a8-ad63fca5cbb4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging (Linear Regression) -> RMSE: 61159678579050176512.0000, MAE: 1163866327838267904.0000, R2: -39231306255768049367254040576.0000\n"
          ]
        }
      ],
      "source": [
        "#evaluate bagged Linear Regression\n",
        "bag_rmse = RegressionEvaluator(\n",
        "    labelCol=\"meter_sale_price\", predictionCol=\"lr_bagging_prediction\", metricName=\"rmse\"\n",
        ").evaluate(lr_ensemble_pred_df)\n",
        "\n",
        "bag_r2 = RegressionEvaluator(\n",
        "    labelCol=\"meter_sale_price\", predictionCol=\"lr_bagging_prediction\", metricName=\"r2\"\n",
        ").evaluate(lr_ensemble_pred_df)\n",
        "\n",
        "bag_mae = RegressionEvaluator(\n",
        "    labelCol=\"meter_sale_price\", predictionCol=\"lr_bagging_prediction\", metricName=\"mae\"\n",
        ").evaluate(lr_ensemble_pred_df)\n",
        "\n",
        "print(f\"Bagging (Linear Regression) -> RMSE: {bag_rmse:.4f}, MAE: {bag_mae:.4f}, R2: {bag_r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6dlT1fJ6amE"
      },
      "source": [
        "## Boosting\n",
        "\n",
        "###spark ML: Gradient Boosted Trees Regressor\n",
        "Spark’s built in boosting for regression is implemented as Gradient Boosted Trees.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38awP6iz6amE",
        "outputId": "b724090f-5431-4f07-e650-3880c11ad1a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GBT Boosting (Spark) -> RMSE: 116732.9913, MAE: 7318.3339, R2: 0.8571\n"
          ]
        }
      ],
      "source": [
        "# A) Boosting in Spark: Gradient-Boosted Trees Regressor\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "\n",
        "gbt = GBTRegressor(\n",
        "    featuresCol=\"scaled_features\",\n",
        "    labelCol=\"meter_sale_price\",\n",
        "    maxDepth=5,\n",
        "    maxIter=100,\n",
        "    stepSize=0.1,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "gbt_model = gbt.fit(train_df)\n",
        "gbt_pred = gbt_model.transform(test_df)\n",
        "\n",
        "gbt_rmse = evaluator_rmse.evaluate(gbt_pred)\n",
        "gbt_r2 = evaluator_r2.evaluate(gbt_pred)\n",
        "gbt_mae = evaluator_mae.evaluate(gbt_pred)\n",
        "\n",
        "print(f\"GBT Boosting (Spark) -> RMSE: {gbt_rmse:.4f}, MAE: {gbt_mae:.4f}, R2: {gbt_r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGXL0ls86amF"
      },
      "source": [
        "## Quick Comparison Table (Results)\n",
        "\n",
        "After running the cells above, you can compare:\n",
        "- Linear Regression (baseline)\n",
        "- Bagging (Linear Regression)\n",
        "- Boosting (GBT in Spark)\n",
        "\n",
        "Typically:\n",
        "- Bagging mainly reduces variance (often helps unstable models linear regression is already stable, so gains can be modest).\n",
        "- Boosting can reduce bias and capture nonlinear patterns (GBT often improves performance when relationships are nonlinear).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "ensemble_df = pd.DataFrame({\n",
        "    \"model\": [\"BaggingEnsemble\"],\n",
        "    \"rmse\": [rmse_ensemble]\n",
        "})\n",
        "\n",
        "ensemble_df.to_csv(\n",
        "    \"ensemble_metrics.csv\",\n",
        "    index=False\n",
        ")"
      ],
      "metadata": {
        "id": "G0P0CRyx9Tez"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}